{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e78b772-82a6-40d0-8013-30fe215af9e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab: Build a Book Recommendation *Agent* with One MCP Tool (Goodreads)\n",
    "\n",
    "## What this lab is about\n",
    "\n",
    "In this lab you will build a **book recommendation AI agent** that uses the **Model Context Protocol (MCP)** to call an external tool. The agent reads a real Goodreads dataset and decides — on its own — whether a user's question requires looking up the data or can be answered directly.\n",
    "\n",
    "This teaches the central idea behind agentic AI: **an LLM that can choose to act**, not just generate text.\n",
    "\n",
    "---\n",
    "\n",
    "## How the system fits together\n",
    "\n",
    "```\n",
    "User question\n",
    "      │\n",
    "      ▼\n",
    "┌─────────────────────┐\n",
    "│   Agent (policy)    │  ← decides: call tool, or answer directly?\n",
    "└────────┬────────────┘\n",
    "         │  tool call (structured JSON)\n",
    "         ▼\n",
    "┌─────────────────────┐\n",
    "│   MCP Server        │  ← exposes recommend_books() as a callable tool\n",
    "└────────┬────────────┘\n",
    "         │  queries\n",
    "         ▼\n",
    "┌─────────────────────┐\n",
    "│  Goodreads CSV      │  ← the ground-truth data source\n",
    "└─────────────────────┘\n",
    "         │  structured results (JSON list)\n",
    "         ▼\n",
    "Agent formats → natural language response → User\n",
    "```\n",
    "\n",
    "There are **three distinct components** you will build:\n",
    "\n",
    "| Component | What it does | Where in the lab |\n",
    "|-----------|-------------|------------------|\n",
    "| **Recommender function** | Filters/sorts the CSV | Steps 3–4 |\n",
    "| **MCP Server** | Exposes that function as a network-callable tool | Steps 5–6 |\n",
    "| **Agent** | Decides when to call the tool vs. answer directly | Steps 7–8 |\n",
    "\n",
    "You will:\n",
    "1. Load a trimmed Goodreads dataset (CSV)\n",
    "2. Wrap a recommendation function as an **MCP tool** (`recommend_books`)\n",
    "3. Run an MCP server (HTTP) that exposes that tool\n",
    "4. Connect a client and verify tool calls work\n",
    "5. Build a simple agent loop that decides *when* to call the tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f63b183c-6093-4622-b549-a212d33e0cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab you will be able to:\n",
    "\n",
    "- **Explain MCP in plain language**: it is a standard way for an agent to discover and call tools, similar to how a USB-C port standardizes how devices connect — any MCP agent can plug into any MCP server.\n",
    "- **Build and run an MCP server** that exposes a single Python function as a callable tool over HTTP.\n",
    "- **Call a tool from a client** and interpret the structured JSON results.\n",
    "- **Implement a minimal agent policy**: the logic that decides whether to call the tool or answer a question directly from the agent's own knowledge.\n",
    "- **Articulate the difference** between a *hallucinated* response (the agent makes up book ratings) and a *grounded* response (the agent reads real data from the CSV).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dc80bfc-b240-4668-9e69-b76cd72b7d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Before You Start\n",
    "\n",
    "### 1) The Goodreads CSV\n",
    "\n",
    "This lab uses a cleaned Goodreads dataset. The CSV must have columns for title, author, and average rating (genre/shelf columns are optional but improve recommendations). A compatible file is provided with the lab materials.\n",
    "\n",
    "### 2) Upload the CSV to Databricks\n",
    "\n",
    "In **Databricks Free Edition**, upload the file via the UI:\n",
    "\n",
    "1. Click **Catalog** in the left sidebar → **Add data** → **Upload files**\n",
    "2. Select your CSV and upload it to a Volume (e.g., `/Volumes/workspace/goodreads_lab/goodreads/`)\n",
    "3. Copy the resulting file path — you will paste it into `DATA_PATH` in Step 1\n",
    "\n",
    "In the next step you will set `DATA_PATH` to the location of your CSV, and `SAMPLE_ROWS` to control how many rows to load (smaller = faster iteration).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccd0ac78-37fc-419d-9760-aa60b43ceb61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 0 — Install Dependencies\n",
    "\n",
    "Before any code can run, we need two Python packages:\n",
    "\n",
    "- **`fastmcp`** — a Python library that makes it easy to create an MCP server. It handles the HTTP transport, tool registration, and the MCP protocol framing so you don't have to write that boilerplate yourself.\n",
    "- **`pandas`** — for loading and querying the Goodreads CSV. It gives us the DataFrame that the recommender logic will filter and sort.\n",
    "\n",
    "The `%pip install` magic works inside Databricks notebooks and installs packages into the current cluster environment. After installing new packages, Databricks requires a Python interpreter restart (the next cell handles this) so the newly installed modules are importable.\n",
    "\n",
    "> **Why `fastmcp` and not the raw MCP SDK?** `fastmcp` is a high-level wrapper that lets you turn a plain Python function into an MCP tool with a single decorator (`@mcp.tool`). It is the fastest way to understand MCP without drowning in protocol details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5585d920-e638-420d-9547-acea2b98cb94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q fastmcp pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04eb378-c866-4e29-8086-e6c1c46cd490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "089b9b5a-a4a9-4f91-9907-2a8358232b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1 — Point to Your Goodreads CSV\n",
    "\n",
    "This cell sets two configuration constants used by every subsequent step:\n",
    "\n",
    "- **`DATA_PATH`** — the full path to your CSV inside Databricks. Update this to wherever you uploaded the file in the prerequisite step. Databricks Volumes paths look like `/Volumes/<catalog>/<schema>/<volume>/<filename>.csv`.\n",
    "- **`SAMPLE_ROWS`** — how many rows to read from the CSV. The full Goodreads dataset can be large; loading 20,000 rows is fast and more than enough for this lab. Set this to `None` to load everything.\n",
    "\n",
    "These constants feed directly into the data loading cell below — nothing runs against the file yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fd08ced-1e40-475d-85e2-70102396dbc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Update this path for your class dataset\n",
    "DATA_PATH = \"/Volumes/workspace/goodreads_lab/goodreads/goodreads_clean.csv\"\n",
    "\n",
    "# We'll also define a small constant for how many rows to load while experimenting.\n",
    "# You can set SAMPLE_ROWS = None to load everything.\n",
    "SAMPLE_ROWS = 20000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4864fb2-7e71-48e2-b969-df3ac90dc493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2 — Load and Inspect the Dataset\n",
    "\n",
    "This cell reads the CSV from disk into a Pandas **DataFrame** — an in-memory table where each row is a book and each column is a field (title, author, rating, etc.).\n",
    "\n",
    "**What the code does, line by line:**\n",
    "\n",
    "- `dbfs_to_local(path)` — a small helper that maps Databricks file paths to the local filesystem path that Python can open directly. In Free Edition, DBFS paths and local paths are often identical, so this is a no-op, but it makes the code portable.\n",
    "- `pd.read_csv(..., nrows=SAMPLE_ROWS)` — reads only the first `SAMPLE_ROWS` rows, which speeds up iteration during development. `low_memory=False` prevents Pandas from misidentifying column types on mixed-type columns (common in user-generated datasets like Goodreads).\n",
    "- The final `print` and `df.head(5)` let you **visually inspect** that the data loaded correctly — always do this before building anything on top of the data.\n",
    "\n",
    "**Connection to the architecture:** This DataFrame is the ground-truth source of information for the entire system. Every book recommendation the agent ever gives will trace back to this table — not to anything the LLM invented. That is the whole point of data grounding.\n",
    "\n",
    "> **Troubleshooting:** If this cell fails, the most common causes are (1) `DATA_PATH` is wrong, (2) the CSV uses a semicolon delimiter instead of a comma (add `sep=';'`), or (3) an encoding issue (add `encoding='latin-1'`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04220fa2-fb26-47f5-9ac8-da6ef63972e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def dbfs_to_local(path):    return path\n",
    "\n",
    "local_path = dbfs_to_local(DATA_PATH)\n",
    "\n",
    "if SAMPLE_ROWS is not None:\n",
    "    df = pd.read_csv(local_path, nrows=SAMPLE_ROWS, low_memory=False)\n",
    "else:\n",
    "    df = pd.read_csv(local_path, low_memory=False)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2f6e53f-7f24-46e2-afed-559c4488a72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3 — Normalize the Columns We Need\n",
    "\n",
    "Goodreads datasets from different sources use different column names. One version calls it `author`, another calls it `authors` or `book_authors`. This cell creates a **unified schema** with exactly four columns — `title`, `authors`, `average_rating`, and `genres` — regardless of what the raw CSV calls them.\n",
    "\n",
    "**What the code does:**\n",
    "\n",
    "- `first_existing(cols, candidates)` — a small helper that scans a list of candidate column names and returns the first one that actually exists in the DataFrame. This makes the lab resilient to naming differences across dataset versions.\n",
    "- The four `*_col` variables capture which actual column name was detected for each logical field. They are printed so you can verify the mapping is correct.\n",
    "- `assert` statements act as **guardrails**: if the dataset is missing title, author, or rating data entirely, the cell fails loudly with an informative message rather than silently producing wrong results downstream.\n",
    "- The final cleanup steps — `dropna`, `clip`, `drop_duplicates` — ensure the recommender won't crash on missing ratings or return the same book twice.\n",
    "\n",
    "**Connection to the architecture:** The `books` DataFrame produced by this cell is the data source the recommender function will query in Step 4. Standardizing the schema here means the recommender can be written once and work with any compatible Goodreads CSV.\n",
    "\n",
    "> **If this cell fails:** Check the printed column names from Step 2 and add your dataset's actual column names to the appropriate `candidates` list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1eefc52-48d6-40f1-96f5-7e8091f29984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def first_existing(cols, candidates) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "cols = set(df.columns)\n",
    "\n",
    "title_col  = first_existing(cols, [\"title\", \"book_title\", \"name\"])\n",
    "author_col = first_existing(cols, [\"authors\", \"author\", \"book_authors\"])\n",
    "rating_col = first_existing(cols, [\"average_rating\", \"avg_rating\", \"rating\", \"ratings_avg\"])\n",
    "genres_col = first_existing(cols, [\"genres\", \"genre\", \"popular_shelves\", \"shelves\", \"tags\", \"subjects\"])\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\" title_col :\", title_col)\n",
    "print(\" author_col:\", author_col)\n",
    "print(\" rating_col:\", rating_col)\n",
    "print(\" genres_col:\", genres_col)\n",
    "\n",
    "assert title_col is not None, \"Couldn't find a title column. Update the candidate list above.\"\n",
    "assert author_col is not None, \"Couldn't find an author/authors column. Update the candidate list above.\"\n",
    "assert rating_col is not None, \"Couldn't find a rating column. Update the candidate list above.\"\n",
    "\n",
    "books = pd.DataFrame({\n",
    "    \"title\": df[title_col].astype(str),\n",
    "    \"authors\": df[author_col].astype(str),\n",
    "    \"average_rating\": pd.to_numeric(df[rating_col], errors=\"coerce\"),\n",
    "})\n",
    "\n",
    "if genres_col is not None:\n",
    "    books[\"genres\"] = df[genres_col].astype(str)\n",
    "else:\n",
    "    books[\"genres\"] = \"\"\n",
    "\n",
    "books = books.dropna(subset=[\"average_rating\"])\n",
    "books[\"average_rating\"] = books[\"average_rating\"].clip(lower=0, upper=5)\n",
    "books = books.drop_duplicates(subset=[\"title\", \"authors\"])\n",
    "\n",
    "print(\"Normalized rows:\", len(books))\n",
    "books.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e6c8f75-d3ea-42f0-859e-db252e5631ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4 — Write the Recommender Function\n",
    "\n",
    "This is the **core retrieval logic** — the function that searches the dataset and returns book matches. It is intentionally simple: no machine learning, no embeddings, no vector database. Just keyword matching and rating filtering.\n",
    "\n",
    "**Why keep it simple?** The goal of this lab is to understand agent architecture and MCP tool calling, not to build a state-of-the-art recommender. A simple function makes the data flow transparent and easy to debug.\n",
    "\n",
    "**What `recommend_books_local` does, step by step:**\n",
    "\n",
    "1. **Tokenize the query** — `re.findall(r\"[a-z0-9']+\", q)` extracts individual words from the user's query string and discards tokens shorter than 3 characters (which are usually filler words).\n",
    "2. **Build a boolean mask** — for each keyword, it checks whether that keyword appears anywhere in the book's `title` or `genres` columns (case-insensitive). Keywords are OR'd together: a book matches if *any* keyword appears.\n",
    "3. **Apply the rating filter** — only books with `average_rating >= min_rating` pass through.\n",
    "4. **Sort and truncate** — results are sorted by rating (highest first) and limited to `max_results`.\n",
    "5. **Return structured data** — a plain Python list of dicts with four keys: `title`, `authors`, `average_rating`, `genres`. This structure matters: the MCP tool will return this exact format, and the agent will format it into readable text for the user.\n",
    "\n",
    "**Connection to the architecture:** This local function is the pure Python brain of the recommender. It knows nothing about MCP, HTTP, or agents — it just takes a query string and returns matching books. In Step 5 you will *wrap* this function in an MCP tool so that any agent can call it over a network, not just code in the same file.\n",
    "\n",
    "The sanity check at the bottom runs the function directly (without MCP) so you can verify it returns sensible results before adding networking complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5c7fc6-d2cd-4d66-96a5-19cb640128ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def recommend_books_local(\n",
    "    user_query: str,\n",
    "    max_results: int = 5,\n",
    "    min_rating: float = 3.8\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Return top-rated books matching a simple keyword query.\"\"\"\n",
    "    q = (user_query or \"\").strip().lower()\n",
    "    keywords = [t for t in re.findall(r\"[a-z0-9']+\", q) if len(t) >= 3]\n",
    "\n",
    "    mask = pd.Series([True] * len(books))\n",
    "    if keywords:\n",
    "        title_text = books[\"title\"].str.lower()\n",
    "        genre_text = books[\"genres\"].str.lower()\n",
    "        mask = pd.Series([False] * len(books))\n",
    "        for kw in keywords:\n",
    "            mask = mask | title_text.str.contains(re.escape(kw), na=False) | genre_text.str.contains(re.escape(kw), na=False)\n",
    "\n",
    "    filtered = books.loc[mask].copy()\n",
    "    filtered = filtered.loc[filtered[\"average_rating\"] >= float(min_rating)]\n",
    "    filtered = filtered.sort_values([\"average_rating\", \"title\"], ascending=[False, True]).head(int(max_results))\n",
    "\n",
    "    results = []\n",
    "    for _, row in filtered.iterrows():\n",
    "        results.append({\n",
    "            \"title\": row[\"title\"],\n",
    "            \"authors\": row[\"authors\"],\n",
    "            \"average_rating\": float(row[\"average_rating\"]),\n",
    "            \"genres\": row.get(\"genres\", \"\"),\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Quick sanity check:\n",
    "recommend_books_local(\"fantasy\", max_results=5, min_rating=4.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "238923a2-a7a4-44e9-a11c-8aa9b38c18d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5 — Wrap the Recommender as an MCP Tool\n",
    "\n",
    "This is where the recommender function becomes a **tool** — something an agent can discover and call at runtime, rather than a function that must be imported and called directly in code.\n",
    "\n",
    "**What MCP is doing here:**\n",
    "\n",
    "The Model Context Protocol (MCP) standardizes the way agents interact with tools. Think of it as a USB-C port for AI tools: any MCP-compatible agent can connect to any MCP-compatible server and discover what tools it offers, what arguments those tools accept, and how to call them — all without custom integration code.\n",
    "\n",
    "**What the code does, line by line:**\n",
    "\n",
    "- `FastMCP(\"Goodreads Recommender\")` — creates an MCP server object with a human-readable name. This name appears in logs and in any MCP Inspector UI you connect to it.\n",
    "- `@mcp.tool` — this decorator is where the magic happens. FastMCP reads the function's name, type annotations (`str`, `int`, `float`), default values, and docstring, and automatically generates a **JSON Schema** tool definition. That schema is what the agent reads to know how to call the tool — it is the formal contract between server and client.\n",
    "- The **docstring** is critical. When a real LLM agent is choosing between tools, the docstring is the primary signal it uses to decide whether this tool is relevant to the user's request. Writing a clear, example-rich docstring is as important as writing the function logic.\n",
    "- Inside the function body, we call `recommend_books_local(...)` — the function from Step 4. The MCP wrapper adds zero logic; it only adds network accessibility.\n",
    "\n",
    "**Connection to the architecture:** After this step, `recommend_books` exists both as a local Python function *and* as an MCP tool. The MCP server (started in Step 6) will serve it over HTTP at a fixed URL. Anything — an agent, a test script, an MCP Inspector — can call it by sending a POST request to that URL with the required arguments as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e294c9b7-6e6e-4353-9dad-352349f04a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Goodreads Recommender\")\n",
    "\n",
    "@mcp.tool\n",
    "def recommend_books(user_query: str, max_results: int = 5, min_rating: float = 3.8):\n",
    "    \"\"\"Recommend books from the Goodreads dataset.\n",
    "\n",
    "    Use this tool when the user asks for book recommendations like:\n",
    "    - 'recommend dystopian novels'\n",
    "    - 'suggest books like Toni Morrison'\n",
    "    - 'I want highly rated literary fiction'\n",
    "\n",
    "    Args:\n",
    "        user_query: What the user is looking for (keywords, genre, vibe).\n",
    "        max_results: How many recommendations to return.\n",
    "        min_rating: Only return books with rating >= this threshold.\n",
    "    \"\"\"\n",
    "    return recommend_books_local(user_query=user_query, max_results=max_results, min_rating=min_rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a16cad52-31ec-4774-81d3-f876e389f807",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6 — Start the MCP Server\n",
    "\n",
    "An MCP server is just an HTTP server that speaks the MCP protocol. In a production deployment, it would run as its own process or container. In this notebook, we run it in a **background thread** so the Databricks kernel stays free for the rest of the cells.\n",
    "\n",
    "**What the code does:**\n",
    "\n",
    "- `HOST` and `PORT` define where the server listens. `127.0.0.1` means it only accepts connections from within the same machine (the Databricks driver node), which is appropriate for this lab.\n",
    "- `run_server()` calls `mcp.run(transport=\"http\", ...)`, which starts a Uvicorn ASGI web server under the hood. FastMCP uses Uvicorn (the same web server that powers many production Python APIs) to handle the HTTP transport layer.\n",
    "- `threading.Thread(target=run_server, daemon=True)` — running the server in a daemon thread means it will automatically shut down when the notebook kernel stops, so you don't accumulate orphaned server processes.\n",
    "- `time.sleep(1.0)` — gives the server one second to fully start before the next cell tries to connect to it. Without this pause, the client might try to connect before the port is open.\n",
    "\n",
    "**What the MCP endpoint looks like:** Once running, the server exposes its tools at `http://127.0.0.1:8000/mcp`. Any MCP client that connects to this URL can:\n",
    "1. Call `tools/list` to discover what tools are available and their JSON Schema definitions\n",
    "2. Call `tools/call` with a tool name and arguments to execute the tool\n",
    "\n",
    "**Connection to the architecture:** This is the moment the recommender function becomes network-accessible. From this point on, nothing else in the lab needs to `import` the recommender function directly — it is an external service that any client can call over HTTP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4cfe659-bfe5-4431-ac79-b99d07b5159e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import threading, time\n",
    "\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = 8000\n",
    "\n",
    "def run_server():\n",
    "    # FastMCP will start an HTTP server; endpoint will be http://HOST:PORT/mcp\n",
    "    mcp.run(transport=\"http\", host=HOST, port=PORT)\n",
    "\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "time.sleep(1.0)\n",
    "print(f\"MCP server running at http://{HOST}:{PORT}/mcp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc26ea32-c758-4e82-8448-46cfcc6de8f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7 — Connect a Client and Call the Tool\n",
    "\n",
    "Now that the server is running, this cell tests the full round-trip: **client → MCP server → tool → results**. This proves the wiring is correct before adding agent logic on top.\n",
    "\n",
    "**What `MockClient` is and why it exists:**\n",
    "\n",
    "In a real MCP deployment, you would use an official MCP client library (like the `fastmcp` client or the Anthropic SDK's tool-use API) that speaks the HTTP protocol to the server. Here, `MockClient` is a lightweight stand-in that mimics the MCP client interface (`list_tools`, `call_tool`) but calls the local function directly instead of making HTTP requests.\n",
    "\n",
    "This is a **testing pattern** called a mock or stub — it lets you verify the client/server interface contract (what methods exist, what they return) without requiring a live network connection. It also means this cell works even if the background server thread has not started yet.\n",
    "\n",
    "**What the `async` / `await` keywords mean:**\n",
    "\n",
    "The mock client uses Python's `async`/`await` syntax because real MCP clients are asynchronous — they wait for network responses without blocking the entire program. The `async with client:` pattern ensures the client connection is opened before use and closed cleanly afterward (equivalent to a try/finally block). In a Databricks notebook, you call async functions with `await` directly.\n",
    "\n",
    "**What `client_smoke_test` checks:**\n",
    "\n",
    "1. `list_tools()` — verifies the server advertises the `recommend_books` tool. In a real system this would return the full JSON Schema definition.\n",
    "2. `call_tool(\"recommend_books\", {...})` — makes an actual tool call with a sample query and prints the returned list of book dicts.\n",
    "\n",
    "**Connection to the architecture:** This is the **client side of MCP**. Everything above this step was building the server. Here you see what the agent will see when it calls the tool: a list of dictionaries, each with `title`, `authors`, `average_rating`, and `genres`. The agent's job (Step 8) is to turn that structured data into a natural-language response.\n",
    "\n",
    "> **If this fails:** Re-run the server cell (Step 6) and wait a moment, then retry this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a95833e-223a-478a-838c-0f61b73b1a0f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Connect with a mock client and call the tool"
    }
   },
   "outputs": [],
   "source": [
    "class MockClient:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "    async def __aenter__(self):\n",
    "        return self\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "    async def list_tools(self):\n",
    "        return [type('Tool', (), {'name': 'recommend_books'})()]\n",
    "    async def call_tool(self, tool_name, args):\n",
    "        if tool_name == \"recommend_books\":\n",
    "            return type('Result', (), {'data': recommend_books_local(**args)})()\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "MCP_URL = f\"http://{HOST}:{PORT}/mcp\"\n",
    "\n",
    "async def client_smoke_test():\n",
    "    client = MockClient(MCP_URL)\n",
    "    async with client:\n",
    "        tools = await client.list_tools()\n",
    "        print(\"Tools exposed by the server:\")\n",
    "        for t in tools:\n",
    "            print(\"-\", t.name)\n",
    "\n",
    "        result = await client.call_tool(\"recommend_books\", {\n",
    "            \"user_query\": \"highly rated dystopian novels\",\n",
    "            \"max_results\": 5,\n",
    "            \"min_rating\": 4.0\n",
    "        })\n",
    "        print(\"\\nTool result data:\")\n",
    "        print(result.data)\n",
    "\n",
    "await client_smoke_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ded67ed1-8107-4a4e-8c3e-a4d1da905bea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 8 — Build the Agent\n",
    "\n",
    "This is the final and most important piece: the **agent** that ties everything together. The agent is the component that decides what to do with a user's message — call the tool, or answer directly.\n",
    "\n",
    "**The two responsibilities of an agent:**\n",
    "\n",
    "| Responsibility | In this lab | In a production system |\n",
    "|---|---|---|\n",
    "| **Policy** (decide what action to take) | `should_call_recommender()` — keyword matching | An LLM reads the message and chooses from available tools |\n",
    "| **Execution** (carry out the action) | `agent_turn()` — calls the MCP tool and formats results | The same loop, but the LLM also formats the final response |\n",
    "\n",
    "**What each function does:**\n",
    "\n",
    "- **`should_call_recommender(user_text)`** — the agent's *policy*. It checks whether the user's message contains any trigger words like \"recommend\", \"suggest\", or \"what should I read\". This is a rule-based policy — simple and transparent. In a real system, an LLM would perform this routing step by reading the user's message and the tool's description.\n",
    "\n",
    "- **`format_recommendations(recs)`** — takes the raw list-of-dicts returned by the MCP tool and formats it into readable text. This is the agent's *output formatting* responsibility. It handles the edge case of empty results (no matches above the rating threshold) gracefully.\n",
    "\n",
    "- **`MockClient`** — the same mock client from Step 7, redefined here so this cell is self-contained.\n",
    "\n",
    "- **`agent_turn(user_text, ...)`** — the **agent loop** itself. This is the heart of the lab:\n",
    "  1. Check the policy: should we call the tool?\n",
    "  2. If yes → create a client, call `recommend_books` via MCP, receive structured results, format them into text, return.\n",
    "  3. If no → return a help message explaining what the agent can do.\n",
    "\n",
    "**Reading the test output at the bottom:**\n",
    "\n",
    "The cell tests two turns back-to-back:\n",
    "- `\"Recommend highly rated gothic novels\"` — contains \"recommend\", so the tool is called. The output is a numbered list of data-backed results.\n",
    "- `\"Why do people like gothic novels?\"` — no trigger words, so the agent responds directly without calling the tool.\n",
    "\n",
    "**Connection to the architecture:** This cell is the **top of the stack**. It uses everything built in Steps 2–7: the normalized DataFrame → the recommender function → the MCP server → the MCP client → this agent loop. When you run the two test turns, the complete data flow executes end-to-end.\n",
    "\n",
    "> **Key insight — grounding vs. hallucination:** When the tool is called, the recommendations come from the actual CSV. The agent cannot invent ratings or book titles that don't exist in the dataset. When the tool is *not* called (the direct-response branch), the agent is free to say anything — which is where hallucination risk lives in real systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d55bf1-f7b8-4b56-90ad-2bee10fdb6a0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent logic with mock client"
    }
   },
   "outputs": [],
   "source": [
    "def should_call_recommender(user_text: str) -> bool:\n",
    "    text = (user_text or \"\").lower()\n",
    "    triggers = [\n",
    "        \"recommend\", \"recommendation\", \"suggest\", \"what should i read\",\n",
    "        \"book like\", \"similar to\", \"any books\", \"looking for\"\n",
    "    ]\n",
    "    return any(t in text for t in triggers)\n",
    "\n",
    "def format_recommendations(recs):\n",
    "    if not recs:\n",
    "        return \"I couldn't find matches above the rating threshold. Try different keywords or lower min_rating.\"\n",
    "    lines = []\n",
    "    for i, b in enumerate(recs, 1):\n",
    "        title = str(b.get(\"title\", \"\")).strip()\n",
    "        authors = str(b.get(\"authors\", \"\")).strip()\n",
    "        rating = b.get(\"average_rating\", None)\n",
    "        genres = b.get(\"genres\", \"\")\n",
    "        line = f\"{i}. {title} — {authors} (rating: {rating})\"\n",
    "        if genres:\n",
    "            line += f\" | genres/tags: {str(genres)[:120]}\"\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "class MockClient:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "    async def __aenter__(self):\n",
    "        return self\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "    async def list_tools(self):\n",
    "        return [type('Tool', (), {'name': 'recommend_books'})()]\n",
    "    async def call_tool(self, tool_name, args):\n",
    "        if tool_name == \"recommend_books\":\n",
    "            return type('Result', (), {'data': recommend_books_local(**args)})()\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "MCP_URL = f\"http://{HOST}:{PORT}/mcp\"\n",
    "\n",
    "async def agent_turn(user_text: str, max_results: int = 5, min_rating: float = 3.8) -> str:\n",
    "    \"\"\"A minimal agent loop: decide whether to call the MCP tool, then respond.\"\"\"\n",
    "    if should_call_recommender(user_text):\n",
    "        client = MockClient(MCP_URL)\n",
    "        async with client:\n",
    "            tool_result = await client.call_tool(\"recommend_books\", {\n",
    "                \"user_query\": user_text,\n",
    "                \"max_results\": max_results,\n",
    "                \"min_rating\": min_rating\n",
    "            })\n",
    "        recs = tool_result.data\n",
    "        return \"Here are some data-backed recommendations from Goodreads:\\n\\n\" + format_recommendations(recs)\n",
    "\n",
    "    return (\n",
    "        \"If you want recommendations, ask something like:\\n\"\n",
    "        \"  • 'Recommend highly rated dystopian novels'\\n\"\n",
    "        \"  • 'Suggest books like Toni Morrison'\\n\\n\"\n",
    "        \"If you want discussion/analysis (no dataset lookup), ask that too.\"\n",
    "    )\n",
    "\n",
    "# Try two turns:\n",
    "print(await agent_turn(\"Recommend highly rated gothic novels\", max_results=5, min_rating=4.0))\n",
    "print(\"\\n---\\n\")\n",
    "print(await agent_turn(\"Why do people like gothic novels?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82262455-15d6-4f92-b9ae-c119d91db06c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 9 — Exercise: Improve the Recommender\n",
    "\n",
    "Now that you understand all three components — the data layer, the MCP tool, and the agent — try extending the system in a small way. The goal is to make sure you can locate *where* to make a change and understand *why* it affects the output.\n",
    "\n",
    "Pick **one** of the following improvements:\n",
    "\n",
    "**Option A — Add popularity filtering** \n",
    "The `books` DataFrame has a `ratings_count` column. Add a `min_reviews: int = 100` parameter to `recommend_books_local` that filters out books with fewer than `min_reviews` ratings. This prevents obscure books with artificially high ratings (e.g., a book with 1 five-star rating) from dominating results. You will also need to update the `@mcp.tool` signature in Step 5 to expose this new parameter.\n",
    "\n",
    "**Option B — Add an 'exclude authors' option** \n",
    "Add an `exclude_authors: str = \"\"` parameter — a comma-separated list of author names to suppress. This is useful when a user says \"recommend fantasy books, but not anything by J.K. Rowling\". Apply the exclusion filter after keyword matching and before rating sorting.\n",
    "\n",
    "**Option C — Better keyword handling** \n",
    "Currently, each keyword in the query is OR'd together: a book matches if *any* keyword appears in title or genres. Change this so quoted phrases are treated as exact sub-string matches. For example, the query `science fiction \"time travel\"` should require `\"time travel\"` to appear as a phrase, while `science` and `fiction` remain OR'd individually.\n",
    "\n",
    "**Option D — Add a 'random' mode** \n",
    "Add a `randomize: bool = False` parameter. When `True`, instead of always returning the *top-N* by rating, return a random sample of N books from among all matches that pass the rating filter. This introduces discovery and variety into recommendations.\n",
    "\n",
    "**Important constraint — keep the MCP architecture intact:** \n",
    "Whichever option you choose, the change should live inside `recommend_books_local` (the tool's implementation). The MCP tool wrapper in Step 5, the server in Step 6, and the agent loop in Step 8 should require only minimal updates to pass through the new parameter. This mirrors how real systems evolve: tool implementations change, but the MCP interface stays stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "164ae80f-a955-4a4a-aa78-14bd4ac97945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 10 — Reflection Questions\n",
    "\n",
    "Answer these questions in a new markdown cell below each one, or in a separate document. They are designed to consolidate your understanding of the architecture you just built.\n",
    "\n",
    "---\n",
    "\n",
    "**1. What did MCP standardize for us?**\n",
    "\n",
    "Without MCP, if you wanted an agent to call your recommender, you would write custom code to serialize arguments, make the HTTP call, parse the response, and handle errors — and you would redo this for every new tool. What specific parts of that work did FastMCP + the MCP protocol handle for you in this lab?\n",
    "\n",
    "---\n",
    "\n",
    "**2. What parts were tool logic vs. agent logic?**\n",
    "\n",
    "Trace through the code and list two or three things that belong in the *tool* (the MCP server) and two or three things that belong in the *agent*. Why is it important to keep these separated? What would break if you mixed them?\n",
    "\n",
    "---\n",
    "\n",
    "**3. Why is it valuable that the tool returns structured data (JSON) instead of plain text?**\n",
    "\n",
    "Imagine the tool returned a formatted string like `\"1. Harry Potter — 4.57 stars\"` instead of a list of dicts. How would that change the agent's ability to filter, sort, or present the data differently depending on context? What does this tell you about the design principle of separating *data* from *presentation*?\n",
    "\n",
    "---\n",
    "\n",
    "**4. Where could hallucination happen in this system?**\n",
    "\n",
    "This lab uses a rule-based policy (`should_call_recommender`). Suppose you replaced that with a real LLM that decides when to call the tool. Identify at least two places in the pipeline where the LLM could introduce incorrect information — and for each, describe a mitigation strategy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbcc590e-d661-4b42-9af5-7b775f077720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "goodreads_mcp_agent_lab (2)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}